{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to get started with Word2Vec — and then how to make it work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is closely adapted from this awesome blog article from Kavita Ganesan: https://medium.freecodecamp.org/how-to-get-started-with-word2vec-and-then-how-to-make-it-work-d0a2fca9dad3.\n",
    "As the title says, we'll learn how to use the Gensim implementation of Word2Vec and actually get it to work. [...] Getting it to work and obtaining useable results depends, as Kavita points out, on the well set-up combination of two things: (1) your input data and (2) your parameter settings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we start with our imports and get logging established:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports needed and logging\n",
    "import gzip\n",
    "import gensim \n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we will work on a dataset from Quora, provided in the scope of the \"Insincere Questions Classification\" on Kaggle. It contains sincere and insincere questions; an insincere question is defined as a question intended to make a statement rather than look for helpful answers. The training data includes the question that was asked, and whether it was identified as insincere (target = 1). The ground-truth labels contain some amount of noise: they are not guaranteed to be perfect. (from: https://www.kaggle.com/c/quora-insincere-questions-classification/data)\n",
    "\n",
    "For working on the data, let's assume we have downloaded and unzipped the dataset (from the source given above), which contains one train.csv and one test.csv table with the textual data and labels.\n",
    "\n",
    "As the dataset is very big, we can create a shortened file with the first few thousand entries at first (we can still use the entire files for the final version of our Training later on). To do this, we need to open the folder containing the train.csv file in a Terminal window (Linux) or a comparable command window that simulates a Linux Terminal in Windows (e.g. the GitLab prompt, or Cygwin). We can then extract the first few thousand lines of train.csv into a shortened file with this Linux command:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "head -n NUMBEROFLINES file.csv > mynewfile.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s take a closer look at our data below by printing the first line(s)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First rows of train_short.csv:  [['qid', 'question_text', 'target'], ['00002165364db923c7e6', 'How did Quebec nationalists see their province as a nation in the 1960s?', '0'], ['000032939017120e6e44', 'Do you have an adopted dog, how would you encourage people to adopt and not shop?', '0'], ['0000412ca6e4628ce2cf', 'Why does velocity affect time? Does velocity affect space geometry?', '0'], ['000042bf85aa498cd78e', 'How did Otto von Guericke used the Magdeburg hemispheres?', '0'], ['0000455dfa3e01eae3af', 'Can I convert montra helicon D to a mountain bike by just changing the tyres?', '0'], ['00004f9a462a357c33be', 'Is Gaza slowly becoming Auschwitz, Dachau or Treblinka for Palestinians?', '0'], ['00005059a06ee19e11ad', 'Why does Quora automatically ban conservative opinions when reported, but does not do the same for liberal views?', '0'], ['0000559f875832745e2e', 'Is it crazy if I wash or wipe my groceries off? Germs are everywhere.', '0'], ['00005bd3426b2d0c8305', 'Is there such a thing as dressing moderately, and if so, how is that different than dressing modestly?', '0']]\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "def csv_to_list(filename):\n",
    "    sents = []\n",
    "    with open(filename, newline='', encoding='utf-8') as csvfile:\n",
    "        csvreader = csv.reader(csvfile, delimiter=',')\n",
    "        for row in csvreader:\n",
    "            sents.append(row)\n",
    "    return sents\n",
    "\n",
    "train_file = 'train_short.csv'\n",
    "train = csv_to_list(train_file)\n",
    "print (\"First rows of train_short.csv: \", train[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll adapt this function a bit now. Let's also do a mild pre-processing of the text using gensim.utils.simple_preprocess (row[1]). We only use the question text itself, and leave the labels whether a question was \"insincere\" or not aside (being not the primary scope of this exercise here).\n",
    "The simple_preprocess function does some basic pre-processing such as tokenization, lowercasing, and so on and returns back a list of tokens (words)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First rows of train_short.csv:  [['question_text'], ['how', 'did', 'quebec', 'nationalists', 'see', 'their', 'province', 'as', 'nation', 'in', 'the'], ['do', 'you', 'have', 'an', 'adopted', 'dog', 'how', 'would', 'you', 'encourage', 'people', 'to', 'adopt', 'and', 'not', 'shop'], ['why', 'does', 'velocity', 'affect', 'time', 'does', 'velocity', 'affect', 'space', 'geometry'], ['how', 'did', 'otto', 'von', 'guericke', 'used', 'the', 'magdeburg', 'hemispheres'], ['can', 'convert', 'montra', 'helicon', 'to', 'mountain', 'bike', 'by', 'just', 'changing', 'the', 'tyres'], ['is', 'gaza', 'slowly', 'becoming', 'auschwitz', 'dachau', 'or', 'treblinka', 'for', 'palestinians'], ['why', 'does', 'quora', 'automatically', 'ban', 'conservative', 'opinions', 'when', 'reported', 'but', 'does', 'not', 'do', 'the', 'same', 'for', 'liberal', 'views'], ['is', 'it', 'crazy', 'if', 'wash', 'or', 'wipe', 'my', 'groceries', 'off', 'germs', 'are', 'everywhere'], ['is', 'there', 'such', 'thing', 'as', 'dressing', 'moderately', 'and', 'if', 'so', 'how', 'is', 'that', 'different', 'than', 'dressing', 'modestly']]\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "def csv_to_list(filename):\n",
    "    sents = []\n",
    "    with open(filename, newline='', encoding='utf-8') as csvfile:\n",
    "        csvreader = csv.reader(csvfile, delimiter=',')\n",
    "        for row in csvreader:\n",
    "            row_text = gensim.utils.simple_preprocess(row[1])\n",
    "            sents.append(row_text)\n",
    "    return sents\n",
    "\n",
    "train_file = 'train_short.csv'\n",
    "sentences = csv_to_list(train_file)\n",
    "print (\"First rows of train_short.csv: \", sentences[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Word2Vec model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-03-26 18:36:17,698 : WARNING : consider setting layer size to a multiple of 4 for greater performance\n",
      "2019-03-26 18:36:17,701 : INFO : collecting all words and their counts\n",
      "2019-03-26 18:36:17,704 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2019-03-26 18:36:17,774 : INFO : PROGRESS: at sentence #10000, processed 120880 words, keeping 14878 word types\n",
      "2019-03-26 18:36:17,831 : INFO : PROGRESS: at sentence #20000, processed 242134 words, keeping 21567 word types\n",
      "2019-03-26 18:36:17,890 : INFO : PROGRESS: at sentence #30000, processed 363093 words, keeping 26675 word types\n",
      "2019-03-26 18:36:17,948 : INFO : PROGRESS: at sentence #40000, processed 484276 words, keeping 30912 word types\n",
      "2019-03-26 18:36:18,007 : INFO : PROGRESS: at sentence #50000, processed 605073 words, keeping 34597 word types\n",
      "2019-03-26 18:36:18,064 : INFO : PROGRESS: at sentence #60000, processed 726181 words, keeping 38005 word types\n",
      "2019-03-26 18:36:18,120 : INFO : PROGRESS: at sentence #70000, processed 848209 words, keeping 41047 word types\n",
      "2019-03-26 18:36:18,179 : INFO : PROGRESS: at sentence #80000, processed 969844 words, keeping 43904 word types\n",
      "2019-03-26 18:36:18,228 : INFO : PROGRESS: at sentence #90000, processed 1091654 words, keeping 46608 word types\n",
      "2019-03-26 18:36:18,357 : INFO : collected 49058 word types from a corpus of 1213051 raw words and 100000 sentences\n",
      "2019-03-26 18:36:18,362 : INFO : Loading a fresh vocabulary\n",
      "2019-03-26 18:36:18,636 : INFO : min_count=2 retains 24820 unique words (50% of original 49058, drops 24238)\n",
      "2019-03-26 18:36:18,636 : INFO : min_count=2 leaves 1188813 word corpus (98% of original 1213051, drops 24238)\n",
      "2019-03-26 18:36:18,783 : INFO : deleting the raw counts dictionary of 49058 items\n",
      "2019-03-26 18:36:18,790 : INFO : sample=0.001 downsamples 48 most-common words\n",
      "2019-03-26 18:36:18,794 : INFO : downsampling leaves estimated 880595 word corpus (74.1% of prior 1188813)\n",
      "2019-03-26 18:36:18,964 : INFO : estimated required memory for 24820 words and 150 dimensions: 42194000 bytes\n",
      "2019-03-26 18:36:18,967 : INFO : resetting layer weights\n",
      "2019-03-26 18:36:19,709 : INFO : training model with 10 workers on 24820 vocabulary and 150 features, using sg=0 hs=0 sample=0.001 negative=5 window=10\n",
      "2019-03-26 18:36:20,778 : INFO : EPOCH 1 - PROGRESS: at 43.77% examples, 381519 words/s, in_qsize 19, out_qsize 0\n",
      "2019-03-26 18:36:21,724 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2019-03-26 18:36:21,741 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2019-03-26 18:36:21,741 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-03-26 18:36:21,745 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-03-26 18:36:21,774 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-03-26 18:36:21,777 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-03-26 18:36:21,789 : INFO : EPOCH 1 - PROGRESS: at 97.49% examples, 425848 words/s, in_qsize 3, out_qsize 1\n",
      "2019-03-26 18:36:21,792 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-03-26 18:36:21,800 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-03-26 18:36:21,813 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-03-26 18:36:21,821 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-03-26 18:36:21,823 : INFO : EPOCH - 1 : training on 1213051 raw words (880211 effective words) took 2.1s, 429252 effective words/s\n",
      "2019-03-26 18:36:22,924 : INFO : EPOCH 2 - PROGRESS: at 49.59% examples, 414047 words/s, in_qsize 19, out_qsize 0\n",
      "2019-03-26 18:36:23,723 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2019-03-26 18:36:23,729 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2019-03-26 18:36:23,738 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-03-26 18:36:23,744 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-03-26 18:36:23,756 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-03-26 18:36:23,761 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-03-26 18:36:23,777 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-03-26 18:36:23,784 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-03-26 18:36:23,790 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-03-26 18:36:23,795 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-03-26 18:36:23,797 : INFO : EPOCH - 2 : training on 1213051 raw words (880877 effective words) took 1.9s, 457899 effective words/s\n",
      "2019-03-26 18:36:24,827 : INFO : EPOCH 3 - PROGRESS: at 52.05% examples, 456187 words/s, in_qsize 19, out_qsize 0\n",
      "2019-03-26 18:36:25,654 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2019-03-26 18:36:25,668 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2019-03-26 18:36:25,679 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-03-26 18:36:25,681 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-03-26 18:36:25,681 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-03-26 18:36:25,685 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-03-26 18:36:25,686 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-03-26 18:36:25,697 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-03-26 18:36:25,701 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-03-26 18:36:25,711 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-03-26 18:36:25,715 : INFO : EPOCH - 3 : training on 1213051 raw words (880759 effective words) took 1.9s, 466678 effective words/s\n",
      "2019-03-26 18:36:26,759 : INFO : EPOCH 4 - PROGRESS: at 49.55% examples, 429394 words/s, in_qsize 19, out_qsize 0\n",
      "2019-03-26 18:36:27,648 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2019-03-26 18:36:27,650 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2019-03-26 18:36:27,659 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-03-26 18:36:27,674 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-03-26 18:36:27,695 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-03-26 18:36:27,701 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-03-26 18:36:27,705 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-03-26 18:36:27,709 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-03-26 18:36:27,713 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-03-26 18:36:27,715 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-03-26 18:36:27,717 : INFO : EPOCH - 4 : training on 1213051 raw words (880197 effective words) took 2.0s, 447262 effective words/s\n",
      "2019-03-26 18:36:28,762 : INFO : EPOCH 5 - PROGRESS: at 43.76% examples, 379238 words/s, in_qsize 19, out_qsize 0\n",
      "2019-03-26 18:36:29,723 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2019-03-26 18:36:29,731 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2019-03-26 18:36:29,763 : INFO : EPOCH 5 - PROGRESS: at 94.72% examples, 413738 words/s, in_qsize 6, out_qsize 3\n",
      "2019-03-26 18:36:29,771 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-03-26 18:36:29,774 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-03-26 18:36:29,776 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-03-26 18:36:29,784 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-03-26 18:36:29,794 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-03-26 18:36:29,798 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-03-26 18:36:29,810 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-03-26 18:36:29,817 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-03-26 18:36:29,817 : INFO : EPOCH - 5 : training on 1213051 raw words (880413 effective words) took 2.1s, 425535 effective words/s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-03-26 18:36:29,820 : INFO : training on a 6065255 raw words (4402457 effective words) took 10.1s, 435584 effective words/s\n"
     ]
    }
   ],
   "source": [
    "# build vocabulary and train model\n",
    "model = gensim.models.Word2Vec(\n",
    "    sentences,\n",
    "    size=150,\n",
    "    window=10,\n",
    "    min_count=2,\n",
    "    workers=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After building the vocabulary, we just need to call train(...) to start training the Word2Vec model. Behind the scenes we are actually training a simple neural network with a single hidden layer. But we are actually not going to use the neural network after training. Instead, the goal is to learn the weights of the hidden layer. These weights are essentially the word vectors that we’re trying to learn.\n",
    "\n",
    "Training on the Word2Vec OpinRank dataset takes about 10–15 minutes. so please be patient while running your code on this dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-03-26 18:38:56,126 : WARNING : Effective 'alpha' higher than previous training cycles\n",
      "2019-03-26 18:38:56,128 : INFO : training model with 10 workers on 24820 vocabulary and 150 features, using sg=0 hs=0 sample=0.001 negative=5 window=10\n",
      "2019-03-26 18:38:57,162 : INFO : EPOCH 1 - PROGRESS: at 48.73% examples, 425511 words/s, in_qsize 20, out_qsize 1\n",
      "2019-03-26 18:38:58,040 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2019-03-26 18:38:58,064 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2019-03-26 18:38:58,080 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-03-26 18:38:58,095 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-03-26 18:38:58,101 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-03-26 18:38:58,108 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-03-26 18:38:58,114 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-03-26 18:38:58,121 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-03-26 18:38:58,124 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-03-26 18:38:58,131 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-03-26 18:38:58,135 : INFO : EPOCH - 1 : training on 1213051 raw words (880623 effective words) took 2.0s, 445600 effective words/s\n",
      "2019-03-26 18:38:59,190 : INFO : EPOCH 2 - PROGRESS: at 41.26% examples, 356261 words/s, in_qsize 20, out_qsize 0\n",
      "2019-03-26 18:39:00,084 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2019-03-26 18:39:00,128 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2019-03-26 18:39:00,141 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-03-26 18:39:00,145 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-03-26 18:39:00,154 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-03-26 18:39:00,196 : INFO : EPOCH 2 - PROGRESS: at 97.15% examples, 423016 words/s, in_qsize 4, out_qsize 1\n",
      "2019-03-26 18:39:00,202 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-03-26 18:39:00,206 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-03-26 18:39:00,208 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-03-26 18:39:00,209 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-03-26 18:39:00,212 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-03-26 18:39:00,212 : INFO : EPOCH - 2 : training on 1213051 raw words (880688 effective words) took 2.0s, 431773 effective words/s\n",
      "2019-03-26 18:39:01,328 : INFO : EPOCH 3 - PROGRESS: at 47.94% examples, 392816 words/s, in_qsize 19, out_qsize 0\n",
      "2019-03-26 18:39:02,155 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2019-03-26 18:39:02,162 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2019-03-26 18:39:02,166 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-03-26 18:39:02,168 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-03-26 18:39:02,174 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-03-26 18:39:02,183 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-03-26 18:39:02,186 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-03-26 18:39:02,194 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-03-26 18:39:02,201 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-03-26 18:39:02,205 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-03-26 18:39:02,210 : INFO : EPOCH - 3 : training on 1213051 raw words (880506 effective words) took 2.0s, 451036 effective words/s\n",
      "2019-03-26 18:39:03,240 : INFO : EPOCH 4 - PROGRESS: at 45.41% examples, 398414 words/s, in_qsize 18, out_qsize 1\n",
      "2019-03-26 18:39:04,063 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2019-03-26 18:39:04,095 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2019-03-26 18:39:04,098 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-03-26 18:39:04,106 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-03-26 18:39:04,111 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-03-26 18:39:04,117 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-03-26 18:39:04,134 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-03-26 18:39:04,139 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-03-26 18:39:04,154 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-03-26 18:39:04,156 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-03-26 18:39:04,157 : INFO : EPOCH - 4 : training on 1213051 raw words (880615 effective words) took 1.9s, 459894 effective words/s\n",
      "2019-03-26 18:39:05,241 : INFO : EPOCH 5 - PROGRESS: at 43.79% examples, 371191 words/s, in_qsize 18, out_qsize 1\n",
      "2019-03-26 18:39:06,178 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2019-03-26 18:39:06,186 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2019-03-26 18:39:06,192 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-03-26 18:39:06,197 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-03-26 18:39:06,208 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-03-26 18:39:06,212 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-03-26 18:39:06,216 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-03-26 18:39:06,227 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-03-26 18:39:06,233 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-03-26 18:39:06,235 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-03-26 18:39:06,236 : INFO : EPOCH - 5 : training on 1213051 raw words (880944 effective words) took 2.0s, 433970 effective words/s\n",
      "2019-03-26 18:39:07,264 : INFO : EPOCH 6 - PROGRESS: at 41.28% examples, 362326 words/s, in_qsize 17, out_qsize 1\n",
      "2019-03-26 18:39:08,296 : INFO : EPOCH 6 - PROGRESS: at 84.09% examples, 364714 words/s, in_qsize 20, out_qsize 0\n",
      "2019-03-26 18:39:08,465 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2019-03-26 18:39:08,473 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2019-03-26 18:39:08,478 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-03-26 18:39:08,478 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-03-26 18:39:08,488 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-03-26 18:39:08,539 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-03-26 18:39:08,543 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-03-26 18:39:08,545 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-03-26 18:39:08,548 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-03-26 18:39:08,552 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-03-26 18:39:08,554 : INFO : EPOCH - 6 : training on 1213051 raw words (880567 effective words) took 2.3s, 385031 effective words/s\n",
      "2019-03-26 18:39:09,647 : INFO : EPOCH 7 - PROGRESS: at 47.92% examples, 399837 words/s, in_qsize 17, out_qsize 2\n",
      "2019-03-26 18:39:10,570 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2019-03-26 18:39:10,576 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2019-03-26 18:39:10,581 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-03-26 18:39:10,586 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-03-26 18:39:10,593 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-03-26 18:39:10,600 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-03-26 18:39:10,605 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-03-26 18:39:10,608 : INFO : worker thread finished; awaiting finish of 2 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-03-26 18:39:10,612 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-03-26 18:39:10,623 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-03-26 18:39:10,626 : INFO : EPOCH - 7 : training on 1213051 raw words (880383 effective words) took 2.0s, 434011 effective words/s\n",
      "2019-03-26 18:39:11,657 : INFO : EPOCH 8 - PROGRESS: at 49.55% examples, 434827 words/s, in_qsize 19, out_qsize 0\n",
      "2019-03-26 18:39:12,492 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2019-03-26 18:39:12,528 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2019-03-26 18:39:12,538 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-03-26 18:39:12,543 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-03-26 18:39:12,548 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-03-26 18:39:12,557 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-03-26 18:39:12,564 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-03-26 18:39:12,570 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-03-26 18:39:12,573 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-03-26 18:39:12,591 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-03-26 18:39:12,594 : INFO : EPOCH - 8 : training on 1213051 raw words (880331 effective words) took 1.9s, 454980 effective words/s\n",
      "2019-03-26 18:39:13,643 : INFO : EPOCH 9 - PROGRESS: at 47.92% examples, 416703 words/s, in_qsize 20, out_qsize 0\n",
      "2019-03-26 18:39:14,524 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2019-03-26 18:39:14,585 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2019-03-26 18:39:14,590 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-03-26 18:39:14,595 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-03-26 18:39:14,600 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-03-26 18:39:14,607 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-03-26 18:39:14,625 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-03-26 18:39:14,634 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-03-26 18:39:14,644 : INFO : EPOCH 9 - PROGRESS: at 99.16% examples, 434428 words/s, in_qsize 1, out_qsize 1\n",
      "2019-03-26 18:39:14,647 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-03-26 18:39:14,649 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-03-26 18:39:14,653 : INFO : EPOCH - 9 : training on 1213051 raw words (880406 effective words) took 2.0s, 436013 effective words/s\n",
      "2019-03-26 18:39:15,703 : INFO : EPOCH 10 - PROGRESS: at 42.93% examples, 372728 words/s, in_qsize 17, out_qsize 2\n",
      "2019-03-26 18:39:16,652 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2019-03-26 18:39:16,665 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2019-03-26 18:39:16,672 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-03-26 18:39:16,679 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-03-26 18:39:16,683 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-03-26 18:39:16,688 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-03-26 18:39:16,697 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-03-26 18:39:16,701 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-03-26 18:39:16,702 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-03-26 18:39:16,718 : INFO : EPOCH 10 - PROGRESS: at 100.00% examples, 434776 words/s, in_qsize 0, out_qsize 1\n",
      "2019-03-26 18:39:16,720 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-03-26 18:39:16,720 : INFO : EPOCH - 10 : training on 1213051 raw words (880790 effective words) took 2.0s, 434056 effective words/s\n",
      "2019-03-26 18:39:16,720 : INFO : training on a 12130510 raw words (8805853 effective words) took 20.6s, 427609 effective words/s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(8805853, 12130510)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train(sentences, total_examples=len(sentences), epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s get to the fun stuff already! Since we trained on user reviews, it would be nice to see similarity on some adjectives. This first example shows a simple look up of words similar to the word 'young'. All we need to do here is to call the most_similar function and provide the word 'young' as the positive example. This returns the top 10 similar words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-03-26 18:41:21,153 : INFO : precomputing L2-norms of word weight vectors\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('teen', 0.7018687725067139),\n",
       " ('teenage', 0.6970053315162659),\n",
       " ('adults', 0.6967407464981079),\n",
       " ('gay', 0.6640512943267822),\n",
       " ('male', 0.6555132269859314),\n",
       " ('sexually', 0.6529505252838135),\n",
       " ('headscarf', 0.6497985124588013),\n",
       " ('female', 0.6405802965164185),\n",
       " ('aged', 0.6368280649185181),\n",
       " ('transgender', 0.6365754008293152)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w1 = \"young\"\n",
    "model.wv.most_similar(positive=w1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('opinions', 0.7783907055854797),\n",
       " ('stance', 0.7686251401901245),\n",
       " ('views', 0.6847450733184814),\n",
       " ('favourite', 0.6429904699325562),\n",
       " ('thoughts', 0.622490406036377),\n",
       " ('classmates', 0.6156018972396851),\n",
       " ('invasions', 0.6017940044403076),\n",
       " ('appearance', 0.5995303392410278),\n",
       " ('observations', 0.5772193670272827),\n",
       " ('enemy', 0.5739162564277649)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2 = \"opinion\"\n",
    "model.wv.most_similar(positive=w2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('italy', 0.8383039236068726),\n",
       " ('germany', 0.8264582753181458),\n",
       " ('france', 0.8190193176269531),\n",
       " ('indonesia', 0.8083047866821289),\n",
       " ('portugal', 0.7982422113418579),\n",
       " ('malaysia', 0.7938610315322876),\n",
       " ('ireland', 0.7936679124832153),\n",
       " ('europe', 0.7907922267913818),\n",
       " ('england', 0.7895593047142029),\n",
       " ('japan', 0.7890664935112)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2 = \"spain\"\n",
    "model.wv.most_similar(positive=w2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you could even use Word2Vec to compute similarity between two words in the vocabulary by invoking the \"similarity(...)\" function and passing in the relevant words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5253688863715762"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Similarity between two different words\n",
    "model.wv.similarity(w1=\"spain\", w2=\"country\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.631107837954425"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Similarity between two different words\n",
    "model.wv.similarity(w1=\"germany\", w2=\"countries\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7719104869073291"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Similarity between two different words\n",
    "model.wv.similarity(w1=\"trump\", w2=\"president\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.776062665288362"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Similarity between two different words\n",
    "model.wv.similarity(w1=\"obama\", w2=\"president\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
